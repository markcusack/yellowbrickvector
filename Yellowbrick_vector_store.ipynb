{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9291d9e5-d404-405f-8307-87d80d0233f2",
   "metadata": {},
   "source": [
    "# Using Yellowbrick as the vector store for ChatGpt\n",
    "\n",
    "This tutorial demonstrates how to create a simple chatbot backed by ChatGpt that uses Yellowbrick as a vector store to support Retrieval Augmented Generation (RAG). What you'll need:\n",
    "\n",
    "1. An account on the [Yellowbrick sandbox](https://cloudlabs.yellowbrick.com/)\n",
    "2. An api key from [OpenAI](https://platform.openai.com/)\n",
    "\n",
    "The tutorial is divided into four parts. First we'll create a simple chatbot to interact with ChatGpt with langchain. Second, we'll add code to create a chatbot that is backed by ChatGpt and uses Yellowbrick as its vector store. Third, we'll show how to create a table in Yellowbrick to store your own embeddings in, and finally we'll describe how to load your own embeddings into your table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5928e9c7-7666-4282-9cb4-00d919228ce0",
   "metadata": {},
   "source": [
    "## Part 1: Creating a chatbot backed by ChatGpt\n",
    "\n",
    "Our chatbot integrates with ChatGpt via the langchain library, so you'll need to install this first. To do this, you should clone this fork of the langchain GitHub project that includes the Yellowbrick vector store connector:\n",
    "1. git clone https://github.com/markcusack/langchain.git\n",
    "2. cd PATH/TO/REPO/langchain/libs/langchain\n",
    "3. pip3 install -e .\n",
    "\n",
    "To get an api key for OpenAI:\n",
    "1. Register at https://platform.openai.com/\n",
    "2. Add a payment method\n",
    "3. Create an API key\n",
    "4. pip3 install openai\n",
    "\n",
    "Install the postgres python connection library:\n",
    "1. pip3 install psycopg2-binary\n",
    "\n",
    "Run the following script, and enter the question \"What is Yellowbrick?\", and see what response you get before we give ChatGpt some additional context about Yellowbrick...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c98adcd-6d80-4211-b2bf-6806e4539fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query using ChatGPT without Yellowbrick vector store integration\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI API key here and hit enter:\")\n",
    "\n",
    "# Set up the chat model and specific prompt\n",
    "\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "system_template=\"\"\"If you don't know the answer, just say that \"I don't know\", don't try to make up an answer.\n",
    "\"\"\"\n",
    "messages = [\n",
    "    SystemMessagePromptTemplate.from_template(system_template),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "]\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, max_tokens=256)  # Modify model_name if you have access to GPT-4\n",
    "chain = LLMChain(llm=llm,\n",
    "                 prompt=prompt,\n",
    "                 verbose=False,\n",
    ")\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "def print_result(result):\n",
    "  output_text = f\"\"\"### Question: \n",
    "  {query}\n",
    "  ### Answer: \n",
    "  {result['text']}\n",
    "  \"\"\"\n",
    "  display(Markdown(output_text))\n",
    "\n",
    "# Use the chain to query\n",
    "\n",
    "while True:\n",
    "  try:\n",
    "    query = input(\"ybChatKB> \")\n",
    "    print_result(chain(query))\n",
    "  except KeyboardInterrupt:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beee89f5-0f1e-4c6e-91a9-44c10762d466",
   "metadata": {},
   "source": [
    "## Part 2: Creating a chatbot backed by ChatGpt that uses Yellowbrick as the vector store\n",
    "\n",
    "Next, we add Yellowbrick as a vector store. The vector store has been populated with embeddings representing\n",
    "all of the Yellowbrick product documentation.\n",
    "\n",
    "Modify the yellowbrick_connection_string use your user name and password, and then run it. Try entering the same question as above, \"What is Yellowbrick?\", and compare the results with the prior run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daa9d4f-7804-4cfa-9873-415998d5e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query using ChatGPT with Yellowbrick vector store integration\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI API key here and hit enter:\")\n",
    "\n",
    "# Change the Yellowbrick connection string to reflect your target instance and database\n",
    "\n",
    "yellowbrick_connection_string = \"postgres://USERNAME:PASSWORD@HOSTNAME:5432/DATABASE\"\n",
    "\n",
    "# Set up the chat model and specific prompt\n",
    "\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "system_template=\"\"\"Use the following pieces of context to answer the users question.\n",
    "Take note of the sources and include them in the answer in the format: \"SOURCES: source1 source2\", use \"SOURCES\" in capital letters regardless of the number of sources.\n",
    "If you don't know the answer, just say that \"I don't know\", don't try to make up an answer.\n",
    "----------------\n",
    "{summaries}\"\"\"\n",
    "messages = [\n",
    "    SystemMessagePromptTemplate.from_template(system_template),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "]\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.vectorstores import Yellowbrick\n",
    "\n",
    "vector_store = Yellowbrick(OpenAIEmbeddings(),\n",
    "                            yellowbrick_connection_string,\n",
    "                            \"oai_embeddings\", # Change the table name to reflect your embeddings\n",
    ")\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, max_tokens=256)  # Modify model_name if you have access to GPT-4\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever(search_kwargs={'k': 5}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "def print_result(result):\n",
    "  output_text = f\"\"\"### Question: \n",
    "  {query}\n",
    "  ### Answer: \n",
    "  {result['answer']}\n",
    "  ### Sources: \n",
    "  {result['sources']}\n",
    "  ### All relevant sources:\n",
    "  {' '.join(list(set([doc.metadata['source'] for doc in result['source_documents']])))}\n",
    "  \"\"\"\n",
    "  display(Markdown(output_text))\n",
    "\n",
    "# Use the chain to query\n",
    "\n",
    "while True:\n",
    "  try:\n",
    "    query = input(\"ybChatKB> \")\n",
    "    print_result(chain(query))\n",
    "  except KeyboardInterrupt:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798c7aa6-5904-4860-b4a9-896fe7681a45",
   "metadata": {},
   "source": [
    "## Part 3: Loading your own document embeddings into Yellowbrick\n",
    "\n",
    "If you want to load your own document embeddings into Yellowbrick, you should create your own table for storing them in. Note that the \n",
    "Yellowbrick database that the table is in has to be UTF-8 encoded. \n",
    "\n",
    "Create a table in a UTF-8 database with the following schema, providing a table name of your choice:\n",
    "\n",
    "<pre>\n",
    "CREATE TABLE oai_embeddings (\n",
    "    id uuid,\n",
    "    embedding_id integer,\n",
    "    text character varying(60000),\n",
    "    metadata character varying(1024),\n",
    "    embedding double precision\n",
    ")\n",
    "DISTRIBUTE ON (id);\n",
    "</pre>\n",
    "\n",
    "**Note**: Be sure to use the same table name in all the scripts to access your embeddings\n",
    "\n",
    "To help, here's a script for connecting to a Yellowbrick instance and creating the table..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72daf30-6160-4ff3-921f-c4c9da329991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Establish connection parameters to Yellowbrick\n",
    "\n",
    "yellowbrick_connection_string = \"postgres://USERNAME:PASSWORD@HOST:5432/DATABASE\"\n",
    "\n",
    "# Establish a connection to the Yellowbrick database\n",
    "try:\n",
    "    conn = psycopg2.connect(yellowbrick_connection_string)\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error connecting to the database: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Create a cursor object using the connection\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Define the SQL statement to create a table\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE my_embeddings (\n",
    "    id uuid,\n",
    "    embedding_id integer,\n",
    "    text character varying(60000),\n",
    "    metadata character varying(1024),\n",
    "    embedding double precision\n",
    ")\n",
    "DISTRIBUTE ON (id);\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query to create a table\n",
    "try:\n",
    "    cursor.execute(create_table_query)\n",
    "    print(\"Table 'my_embeddings' created successfully!\")\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error creating table: {e}\")\n",
    "    conn.rollback()\n",
    "\n",
    "# Commit changes and close the cursor and connection\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62b4150-2aa3-453e-a4db-81a2f8a11e70",
   "metadata": {},
   "source": [
    "## Part 4: Loading your own document embeddings into Yellowbrick\n",
    "\n",
    "If you want to load your own document embeddings into Yellowbrick, you can use the following script..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de914b10-850e-4c5b-a09b-c6a14006637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the embeddings store\n",
    "\n",
    "# Load documents and split them into chunks for conversion to embeddings\n",
    "\n",
    "DOCS_FOLDER = \"/Users/markcusack/llms/yb/dita2md\"  # Folder to check out to\n",
    "REPO_DOCUMENTS_PATH = \"\"  # Set to \"\" to index the whole data folder\n",
    "DOCUMENT_BASE_URL = \"https://yellowbrick.com/resources/product-documentation/\"  # Actual URL\n",
    "DATA_STORE_DIR = \"/Users/markcusack/llms/yb/data_store\"\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "from getpass import getpass\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import Yellowbrick\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI API key here and hit enter:\")\n",
    "\n",
    "# Change the Yellowbrick connection string to reflect your target instance and database\n",
    "\n",
    "yellowbrick_connection_string = \"postgres://USERNAME:PASSWORD@HOST:5432/DATABASE\"\n",
    "\n",
    "# Change the table to reflect your destination table for the embeddings in Yellowbrick\n",
    "\n",
    "table = \"oai_embeddings_2000\"\n",
    "\n",
    "name_filter = \"**/*.md\"\n",
    "separator = \"\\n## \"  # This separator assumes Markdown docs from the repo uses ### as logical main header most of the time\n",
    "chunk_size_limit = 2000\n",
    "max_chunk_overlap = 200\n",
    "\n",
    "repo_path = pathlib.Path(os.path.join(DOCS_FOLDER, REPO_DOCUMENTS_PATH))\n",
    "document_files = list(repo_path.glob(name_filter))\n",
    "\n",
    "def convert_path_to_doc_url(doc_path):\n",
    "  # Convert from relative path to actual document url\n",
    "  return re.sub(f\"{DOCS_FOLDER}/{REPO_DOCUMENTS_PATH}/(.*)\\.[\\w\\d]+\", f\"{DOCUMENT_BASE_URL}/\\\\1\", str(doc_path))\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=open(file, \"r\").read(),\n",
    "        metadata={\"source\": convert_path_to_doc_url(file)}\n",
    "    )\n",
    "    for file in document_files\n",
    "]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size_limit, \n",
    "                                               chunk_overlap=max_chunk_overlap,\n",
    "                                               separators=[separator, \"\\nn\", \"\\n\", \",\", \" \", \"\"]\n",
    ")\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "docs_text = [doc.page_content for doc in split_docs]\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vector_store = Yellowbrick.from_documents(documents=split_docs, \n",
    "                                          embedding=embeddings, \n",
    "                                          connection_string=yellowbrick_connection_string, \n",
    "                                          table=table\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_venv",
   "language": "python",
   "name": "langchain_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
